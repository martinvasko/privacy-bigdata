Step 1: Create a Spark Session

Step 2: Load sample dataset NCHS_Teen_Birth_Rates_for_Age_Group_15-19_in_the_United_States_by_County.csv

Step 3: Build a bigger dataset by union with copy of dataset itself (60x)
df = df.union(initalDf);

Step 4: Clean up by renaming columns „Lower Confidence Limit“ to „lcl“ and „Upper Confidence Limit“ to „ucl“

Step 5: Transform:

5.1:
mode = "noop"

df = df
                    .withColumn("avg", expr("(lcl+ucl)/2"))
                    .withColumn("lcl2", df.col("lcl"))
                    .withColumn("ucl2", df.col("ucl"));

5.2:
mode = "full"
df = df
                        .drop(df.col("avg"))
                        .drop(df.col("lcl2"))
                        .drop(df.col("ucl2"));

Step 6: Action:
df.collect()